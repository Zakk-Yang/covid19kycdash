{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing NAB ...\n",
      "Completed processing CBA ...\n",
      "Completed processing ANZ ...\n",
      "Completed processing Westpac ...\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from tqdm import tqdm\n",
    "# from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.manifold import TSNE\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "# from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "\n",
    "class coronavirus_news_aggregator():\n",
    "    def __init__(self, client_list=[]):\n",
    "        # Initialize Empty List\n",
    "        self.client_list = client_list\n",
    "\n",
    "    def covid19_news_scraper(self, search_query):\n",
    "        \"\"\"\n",
    "        Pass in a client name or search query and returns last 100 headlines associating the client with Covid-19   \n",
    "        \"\"\"\n",
    "        # Use this URL for Australian centric data\n",
    "        news_url = \"https://news.google.com.au/rss/search?q={\"+str(search_query)+\"%coronavirus}\"\n",
    "        Client = urlopen(news_url)\n",
    "        xml_page = Client.read()\n",
    "        Client.close()\n",
    "        # Beautiful Soup Library is the bomb\n",
    "        soup_page = soup(xml_page,\"xml\")\n",
    "        news_list = soup_page.findAll(\"item\")\n",
    "        \n",
    "        # Two separate lists for News Title and Publication Date\n",
    "        l1 = []\n",
    "        l2 = []\n",
    "        for news in news_list:\n",
    "            # Append to a list\n",
    "            l1.append(news.title.text)\n",
    "            l2.append(news.pubDate.text)\n",
    "            # Zip the two together\n",
    "            l_tup = list(zip(l1, l2))\n",
    "        \n",
    "        # Save this to a DataFrame\n",
    "        df = pd.DataFrame(l_tup, columns=['Title', 'Date'])\n",
    "        # Select Date of Headline\n",
    "        df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "        # Split the Title into Headline and Source columns and then drop the 'Title' column\n",
    "        df[['Headline','Source']] = df['Title'].str.rsplit(\"-\",1,expand=True)\n",
    "        df.drop('Title', axis=1, inplace=True)\n",
    "        df['Client'] = str(search_query)\n",
    "        return df\n",
    "\n",
    "    def sentiment_analyser(self, search_query):\n",
    "        \"\"\"\n",
    "        Runs a Google News Search on the input string and then uses VADER sentiment analysis engine on each returned headline.\n",
    "        Input: Search Query String\n",
    "        Output: DataFrame with compound sentiment score for each news article\n",
    "        \"\"\"\n",
    "        # Create a Covid-19 News DataFrame for each organization of interest\n",
    "        news_df = self.covid19_news_scraper(search_query)\n",
    "        # Initialize VADER Sentiment Intensity Analyzer \n",
    "        sia = SIA()\n",
    "        results = []\n",
    "\n",
    "        # Calculate the polarity score for each headline associated with the organization\n",
    "        for row in news_df['Headline']:\n",
    "            pol_score = sia.polarity_scores(row)\n",
    "            pol_score['Headline'] = row\n",
    "            results.append(pol_score)\n",
    "        \n",
    "        # Create the Sentiment DataFrame\n",
    "        sent_df = pd.DataFrame.from_records(results)\n",
    "        # Merge the two dataframes together on the 'Headline' column\n",
    "        merge_df = news_df.merge(sent_df, on='Headline')\n",
    "        # Re-order and Rename the columns\n",
    "        merge_df = merge_df.rename(columns={'compound':'VADER Score'})\n",
    "        col_order = ['Client','Date','Headline','Source','VADER Score','neg','neu','pos']\n",
    "        print('Completed processing %s' % search_query, \"...\")\n",
    "        return merge_df[col_order]\n",
    "\n",
    "    def client_c19_news_sentiment_agg(self, client_list):\n",
    "        \"\"\"\n",
    "        Provided a list of clients, this pulls up the past 100 covid-19 related news articles on each of them and calculates \n",
    "        a Composite Sentiment score for each article related to a client \n",
    "        \"\"\"\n",
    "        frames = [self.sentiment_analyser(c) for c in client_list]\n",
    "        result = pd.concat(frames)\n",
    "        # print()\n",
    "        # print(\"VADER Score is a Normalized Weighted Sentiment Composite Score that ranges from +1 (Extremely Positive) to -1 (Extremely Negative)\")\n",
    "        return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client_list = ['NAB','CBA','ANZ','Westpac']\n",
    "    cn = coronavirus_news_aggregator()\n",
    "    df = cn.client_c19_news_sentiment_agg(client_list=client_list)\n",
    "    print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>VADER Score</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>ASX drops 2.5pc as oil prices collapse, while ...</td>\n",
       "      <td>ABC News</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>NAB worker sacked over false coronavirus test</td>\n",
       "      <td>The New Daily</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>NAB flags $1.14bn triple hit to H1 result</td>\n",
       "      <td>The West Australian</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>NAB's McEwan vows fight to save jobs in bank r...</td>\n",
       "      <td>Sydney Morning Herald</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>Coronavirus credit card cuts: Which banks have...</td>\n",
       "      <td>Mozo.com.au</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>A huge hit to the business sector from coronav...</td>\n",
       "      <td>Property Observer</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>Coronavirus ASX: Coles, BHP Up, CBA, Westpac, ...</td>\n",
       "      <td>Canstar</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>NAB ramps up temporary branch closures</td>\n",
       "      <td>Sydney Morning Herald</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>NAB expands coronavirus support to credit card...</td>\n",
       "      <td>Mozo.com.au</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NAB</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>Fitch Downgrades NAB to 'A+' on Coronavirus Ri...</td>\n",
       "      <td>Fitch Ratings</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Client        Date                                           Headline  \\\n",
       "0    NAB  2020-04-20  ASX drops 2.5pc as oil prices collapse, while ...   \n",
       "1    NAB  2020-03-24     NAB worker sacked over false coronavirus test    \n",
       "2    NAB  2020-04-20         NAB flags $1.14bn triple hit to H1 result    \n",
       "3    NAB  2020-04-17  NAB's McEwan vows fight to save jobs in bank r...   \n",
       "4    NAB  2020-04-20  Coronavirus credit card cuts: Which banks have...   \n",
       "5    NAB  2020-04-14  A huge hit to the business sector from coronav...   \n",
       "6    NAB  2020-03-23  Coronavirus ASX: Coles, BHP Up, CBA, Westpac, ...   \n",
       "7    NAB  2020-04-07            NAB ramps up temporary branch closures    \n",
       "8    NAB  2020-04-03  NAB expands coronavirus support to credit card...   \n",
       "9    NAB  2020-04-07  Fitch Downgrades NAB to 'A+' on Coronavirus Ri...   \n",
       "\n",
       "                   Source  VADER Score    neg    neu    pos  \n",
       "0                ABC News      -0.4939  0.198  0.802  0.000  \n",
       "1           The New Daily       0.0000  0.000  1.000  0.000  \n",
       "2     The West Australian       0.0000  0.000  1.000  0.000  \n",
       "3   Sydney Morning Herald       0.1531  0.188  0.580  0.232  \n",
       "4             Mozo.com.au      -0.1280  0.323  0.472  0.205  \n",
       "5       Property Observer       0.3182  0.000  0.796  0.204  \n",
       "6                 Canstar       0.0000  0.000  1.000  0.000  \n",
       "7   Sydney Morning Herald       0.0000  0.000  1.000  0.000  \n",
       "8             Mozo.com.au       0.6908  0.000  0.544  0.456  \n",
       "9           Fitch Ratings      -0.7003  0.420  0.580  0.000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "# Basic Imports\n",
    "import nltk\n",
    "import re\n",
    "import numpy as npn\n",
    "import pandas as pd\n",
    "\n",
    "# Import spaCy for Lemmatization\n",
    "import spacy\n",
    "\n",
    "# Gensim for Topic Modeling\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting Tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
